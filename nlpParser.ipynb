{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from stat_parser import Parser, display_tree\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    'Siri, please evaluate two plus three.',\n",
    "    'Call my mom',\n",
    "    'Can you play \"Thriller\" by Michael Jackson?',\n",
    "    \"Tell me about Elon Musk.\",\n",
    "    \"I am doing the second assignment on PracticalAI\"\n",
    "]\n",
    "\n",
    "parser = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipes_structure = [SequencePipe([FindTokensPipe(\"VERB/nsubj/*\"),\n",
    "                                 NamedEntityFilterPipe(),\n",
    "                                 NamedEntityExtractorPipe()]),\n",
    "                   FindTokensPipe(\"VERB\"),\n",
    "                   AnyPipe([SequencePipe([FindTokensPipe(\"VBD/dobj/NNP\"),\n",
    "                                          AggregatePipe([NamedEntityFilterPipe(\"GPE\"), \n",
    "                                                NamedEntityFilterPipe(\"PERSON\")]),\n",
    "                                          NamedEntityExtractorPipe()]),\n",
    "                            SequencePipe([FindTokensPipe(\"VBD/**/*/pobj/NNP\"),\n",
    "                                          AggregatePipe([NamedEntityFilterPipe(\"LOC\"), \n",
    "                                                NamedEntityFilterPipe(\"PERSON\")]),\n",
    "                                          NamedEntityExtractorPipe()])])]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Subject (Who)\n",
    "Action (What)\n",
    "Object (With that)\n",
    "Property (Adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textpipeliner import PipelineEngine, Context\n",
    "from textpipeliner.pipes import *\n",
    "\n",
    "pipes_structure = [AggregatePipe([\n",
    "                                  FindTokensPipe(\"VERB/nsubj/*\")\n",
    "                    ]),\n",
    "                   FindTokensPipe(\"VERB\"),\n",
    "                   AnyPipe([\n",
    "                           FindTokensPipe(\"VERB/dobj/[NOUN,PROPN,PRON]\"),\n",
    "                           AggregatePipe([\n",
    "                               FindTokensPipe(\"VERB/dobj/**/**/*\"),\n",
    "                               FindTokensPipe(\"VERB/dobj/**\")\n",
    "                           ])\n",
    "                    ]),\n",
    "                   \n",
    "                   FindTokensPipe(\"VERB/prep/*\"),\n",
    "                   SequencePipe([\n",
    "                       AggregatePipe([\n",
    "                            FindTokensPipe(\"VERB/prep/**/**/*\"), \n",
    "                       ])\n",
    "                   ])\n",
    "                   \n",
    "                  ]\n",
    "                \n",
    "\n",
    "engine = PipelineEngine(pipes_structure, Context(parser(doc)))\n",
    "f = engine.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call call VERB VB ROOT Xxxx True False\n",
      "my -PRON- ADJ PRP$ poss xx True True\n",
      "mom mom NOUN NN dobj xxx True False\n"
     ]
    }
   ],
   "source": [
    "doc = parser(examples[1])\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call VERB ROOT Call\n",
      "my ADJ poss mom\n",
      "mom NOUN dobj Call\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve(sents):\n",
    "    pipes_structure = [AggregatePipe([\n",
    "                                  FindTokensPipe(\"VERB/nsubj/*\")\n",
    "                    ]),\n",
    "                   FindTokensPipe(\"VERB\"),\n",
    "                   AnyPipe([\n",
    "                           FindTokensPipe(\"VERB/dobj/[NOUN,PROPN,PRON]\"),\n",
    "                           AggregatePipe([\n",
    "                               FindTokensPipe(\"VERB/dobj/**/**/*\"),\n",
    "                               FindTokensPipe(\"VERB/dobj/**\")\n",
    "                           ])\n",
    "                    ]),\n",
    "                   \n",
    "                   FindTokensPipe(\"VERB/prep/*\"),\n",
    "                   SequencePipe([\n",
    "                       AnyPipe([\n",
    "                            FindTokensPipe(\"VERB/prep/**/**/*\"), \n",
    "                            FindTokensPipe(\"VERB/dobj/[NOUN,PROPN,PRON]/**/ADJ\")\n",
    "                       ])\n",
    "                   ])\n",
    "                   \n",
    "                  ]\n",
    "                \n",
    "\n",
    "    for sent in sents:\n",
    "        print(\"Processing sentence:'{}'\".format(sent))\n",
    "        process_result = PipelineEngine(pipes_structure, Context(parser(sent))).process()[0]\n",
    "        result = ['null' if len(res_item) == 0 else \", \".join([y.text for y in res_item]) for res_item in process_result]\n",
    "        print(\"  Subject: {} \\n  Action: {} \\n  Object: {} \\n  Preposition: {} \\n  Properties: {}\".format(*result))\n",
    "        print(\"------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence:'Siri, please evaluate two plus three.'\n",
      "  Subject: null \n",
      "  Action: evaluate \n",
      "  Object: plus, three, two \n",
      "  Preposition: null \n",
      "  Properties: null\n",
      "------------\n",
      "\n",
      "Processing sentence:'Call my mom'\n",
      "  Subject: null \n",
      "  Action: Call \n",
      "  Object: mom \n",
      "  Preposition: null \n",
      "  Properties: my\n",
      "------------\n",
      "\n",
      "Processing sentence:'Can you play \"Thriller\" by Michael Jackson?'\n",
      "  Subject: you \n",
      "  Action: play \n",
      "  Object: Thriller \n",
      "  Preposition: by \n",
      "  Properties: Jackson, Michael\n",
      "------------\n",
      "\n",
      "Processing sentence:'Tell me about Elon Musk.'\n",
      "  Subject: null \n",
      "  Action: Tell \n",
      "  Object: me \n",
      "  Preposition: about \n",
      "  Properties: Musk, Elon\n",
      "------------\n",
      "\n",
      "Processing sentence:'I am doing the second assignment on PracticalAI'\n",
      "  Subject: I \n",
      "  Action: doing \n",
      "  Object: assignment \n",
      "  Preposition: null \n",
      "  Properties: second\n",
      "------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solve(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve2(sents):\n",
    "    \n",
    "    for sent in sents:\n",
    "        doc = parser(sent)\n",
    "        print(\"Sentence: '{}'\".format(sent))\n",
    "        for token in doc:\n",
    "            print(token.text, token.pos_, token.dep_, token.head.text)\n",
    "        print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'Siri, please evaluate two plus three.'\n",
      "Siri PROPN npadvmod evaluate\n",
      ", PUNCT punct evaluate\n",
      "please INTJ intj evaluate\n",
      "evaluate VERB ROOT evaluate\n",
      "two NUM dobj evaluate\n",
      "plus CCONJ cc two\n",
      "three NUM conj two\n",
      ". PUNCT punct evaluate\n",
      "--------\n",
      "Sentence: 'Call my mom'\n",
      "Call VERB ROOT Call\n",
      "my ADJ poss mom\n",
      "mom NOUN dobj Call\n",
      "--------\n",
      "Sentence: 'Can you play \"Thriller\" by Michael Jackson?'\n",
      "Can VERB aux play\n",
      "you PRON nsubj play\n",
      "play VERB ROOT play\n",
      "\" PUNCT punct Thriller\n",
      "Thriller PROPN dobj play\n",
      "\" PUNCT punct Thriller\n",
      "by ADP prep play\n",
      "Michael PROPN compound Jackson\n",
      "Jackson PROPN pobj by\n",
      "? PUNCT punct play\n",
      "--------\n",
      "Sentence: 'Tell me about Elon Musk.'\n",
      "Tell VERB ROOT Tell\n",
      "me PRON dobj Tell\n",
      "about ADP prep Tell\n",
      "Elon PROPN compound Musk\n",
      "Musk PROPN pobj about\n",
      ". PUNCT punct Tell\n",
      "--------\n",
      "Sentence: 'I am doing the second assignment on PracticalAI'\n",
      "I PRON nsubj doing\n",
      "am VERB aux doing\n",
      "doing VERB ROOT doing\n",
      "the DET det assignment\n",
      "second ADJ amod assignment\n",
      "assignment NOUN dobj doing\n",
      "on ADP prep assignment\n",
      "PracticalAI NOUN pobj on\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "solve2(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SBAR+S\n",
      "  (NP (PRP I))\n",
      "  (VP\n",
      "    (VB am)\n",
      "    (VBG doing)\n",
      "    (NP\n",
      "      (NP (DT the) (JJ second) (NN assignment))\n",
      "      (PP (IN on) (NP (NN PracticalAI))))))\n"
     ]
    }
   ],
   "source": [
    "from stat_parser import Parser\n",
    "parser = Parser()\n",
    "trees = parser.parse(examples[4])\n",
    "print(trees)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
